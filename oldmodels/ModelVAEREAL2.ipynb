{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade19a53-9154-49af-a8d1-6136ad278adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import torch.nn.init as init\n",
    "\n",
    "fnexpr='GSE117931/GSE117931_GPL14951.tsv'\n",
    "fnmet='GSE117931/GSE117931_GPL13534.tsv'\n",
    "fnassig='GSE117931/assig.csv'\n",
    "nsamp=37\n",
    "fnmodel='VAEREAL2.pth'\n",
    "filename = \"VAEREAL2-\"\n",
    "ldim=1000\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 4096),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 2 * latent_dim)  # 2 for mean and variance\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 2048),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(4096, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "    def _initialize_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                # He initialization for weights of Linear layers with Leaky ReLU\n",
    "                init.kaiming_normal_(module.weight, nonlinearity='leaky_relu')\n",
    "                if module.bias is not None:\n",
    "                    init.constant_(module.bias, 0)\n",
    "                    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        #logvar = torch.clamp(logvar, min=-3, max=2)\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = torch.chunk(h, 2, dim=1)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decoder(z)\n",
    "        #recon = torch.sigmoid(recon) \n",
    "        return recon, mu, logvar\n",
    "\n",
    "        \n",
    "# Leer datos\n",
    "expression_data = pd.read_csv(fnexpr,sep='\\t', index_col=0)\n",
    "expression_data=expression_data.T\n",
    "methylation_data = pd.read_csv(fnmet,sep='\\t', index_col=0)\n",
    "methylation_data=methylation_data.T\n",
    "assign_data = pd.read_csv(fnassig,sep='\\t')\n",
    "\n",
    "expression_data = expression_data.iloc[:, 1:]\n",
    "methylation_data = methylation_data.iloc[:, 1:]\n",
    "assign_data = assign_data.iloc[:, 1:]\n",
    "\n",
    "# Convertir todas las columnas a tipo float\n",
    "expression_data = expression_data.apply(pd.to_numeric, errors='coerce')\n",
    "methylation_data = methylation_data.apply(pd.to_numeric, errors='coerce')\n",
    "assign_data = assign_data.apply(pd.to_numeric, errors='coerce')\n",
    "# Lidiar con valores NaN (si los hay). \n",
    "\n",
    "methylation_data.dropna(axis=1, inplace=True)\n",
    "#expression_data.fillna(0, inplace=True)\n",
    "#methylation_data.fillna(0, inplace=True)\n",
    "#assign_data.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Normalizacion\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "expression_data_scaled = scaler.fit_transform(expression_data)\n",
    "methylation_data_scaled = scaler.fit_transform(methylation_data)\n",
    "assign_data_scaled =assign_data\n",
    "\n",
    "# Convertir de vuelta a DataFrames\n",
    "expression_data = pd.DataFrame(expression_data_scaled, index=expression_data.index, columns=expression_data.columns)\n",
    "methylation_data = pd.DataFrame(methylation_data_scaled, index=methylation_data.index, columns=methylation_data.columns)\n",
    "assign_data = pd.DataFrame(assign_data_scaled, index=assign_data.index, columns=assign_data.columns)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device=\"cpu\"\n",
    "\n",
    "# Convertirlos a tensores y pasarlos a la GPU\n",
    "expression_data = torch.FloatTensor(expression_data.values).to(device)\n",
    "methylation_data = torch.FloatTensor(methylation_data.values).to(device)\n",
    "assign_data = torch.FloatTensor(assign_data.values).to(device)\n",
    "\n",
    "combined_data = torch.cat((expression_data,methylation_data,assign_data), 1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1569ad78-f294-47e5-bdbf-d90cb574a303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo VAE tiene 3557617933 parÃ¡metros entrenables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14215/673808169.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(torch.round(torch.tensor(recon_data), decimals=4))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5193, 0.0827, 0.4921,  ..., 0.2198, 0.5703, 0.1296],\n",
      "        [0.3244, 0.7907, 0.7732,  ..., 0.0472, 0.9180, 0.0830],\n",
      "        [0.1522, 0.0590, 0.5235,  ..., 0.0181, 0.8340, 0.2768],\n",
      "        ...,\n",
      "        [0.1656, 0.3640, 0.2348,  ..., 0.3618, 0.0932, 0.1347],\n",
      "        [0.0731, 0.1502, 0.9360,  ..., 0.1884, 0.8343, 0.0535],\n",
      "        [0.0516, 0.3556, 0.0428,  ..., 0.2275, 0.3575, 0.3606]])\n",
      "tensor(1.5590e-05, grad_fn=<MinBackward1>)\n",
      "tensor(1.0000, grad_fn=<MaxBackward1>)\n",
      "0.0003070642414968461\n",
      "-0.00021073764946777374\n",
      "0.0003085977805312723\n",
      "-0.0002122193545801565\n",
      "0.0010312972590327263\n",
      "-0.0006930335075594485\n",
      "0.0003924948687199503\n",
      "-0.0002686259977053851\n",
      "0.0012912177480757236\n",
      "-0.0006611050921492279\n",
      "0.00039366839337162673\n",
      "-0.0001985938724828884\n",
      "0.0011427294230088592\n",
      "-0.0005364313838072121\n",
      "0.00040735318907536566\n",
      "-0.00019133725436404347\n",
      "0.0002629574737511575\n",
      "-0.00026594565133564174\n",
      "8.866641292115673e-05\n",
      "-3.267673673690297e-05\n",
      "0.0002209792728535831\n",
      "-4.82696013932582e-05\n",
      "5.195301127969287e-05\n",
      "-2.781150897135376e-06\n",
      "3.1047395623318153e-06\n",
      "-2.947993834823137e-06\n",
      "4.811564053852635e-07\n",
      "-4.694726953857753e-07\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor(nan, grad_fn=<MinBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "NaN detected!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m real_data \u001b[38;5;241m=\u001b[39m combined_data[idx:idx\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     33\u001b[0m vae_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 35\u001b[0m recon_data, mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (idx \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28mprint\u001b[39m(real_data)\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 68\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m mu, logvar \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mchunk(h, \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(mu, logvar)\n\u001b[0;32m---> 68\u001b[0m recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#recon = torch.sigmoid(recon) \u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recon, mu, logvar\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## # Modelos y optimizadores\n",
    "vae = VAE(combined_data.shape[1],ldim).to(device)\n",
    "print(f'El modelo VAE tiene {count_parameters(vae)} parÃ¡metros entrenables.')\n",
    "vae_optimizer = optim.RMSprop(vae.parameters(), lr=0.0002)\n",
    "\n",
    "# ParÃ¡metros de KL Annealing\n",
    "kl_weight = 0.0  # Peso inicial de la divergencia KL\n",
    "kl_weight_max = 1.0  # Peso mÃ¡ximo que alcanzarÃ¡ la divergencia KL\n",
    "kl_annealing_epochs = 2000  # NÃºmero de Ã©pocas para alcanzar el peso mÃ¡ximo\n",
    "\n",
    "# FunciÃ³n de pÃ©rdida para VAE con KL Annealing\n",
    "def loss_vae_with_kl_annealing(recon_x, x, mu, logvar, kl_weight):\n",
    "    recon_loss = nn.MSELoss(reduction='sum')(recon_x, x)  # pÃ©rdida de reconstrucciÃ³n\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())  # divergencia KL\n",
    "    total_loss = recon_loss + kl_weight * kl_divergence\n",
    "    return total_loss, recon_loss, kl_divergence\n",
    "\n",
    "# Entrenamiento\n",
    "n_samples = combined_data.size(0)\n",
    "batch_size = 8\n",
    "n_epochs = 10000\n",
    "start_time = time.time()\n",
    "best_loss = float('inf')\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_recon_loss = 0.0\n",
    "    epoch_kl_divergence = 0.0\n",
    "    # Actualizar el peso de la divergencia KL\n",
    "    kl_weight = min(kl_weight_max, kl_weight + (kl_weight_max / kl_annealing_epochs))\n",
    "\n",
    "    for idx in range(0, n_samples, batch_size):\n",
    "        real_data = combined_data[idx:idx+batch_size].to(device)\n",
    "\n",
    "        vae_optimizer.zero_grad()\n",
    "        \n",
    "        recon_data, mu, logvar = vae(real_data)\n",
    "        if ((epoch+1) % 100 == 0) and (idx ==0):\n",
    "                print(real_data)\n",
    "                print(torch.round(torch.tensor(recon_data), decimals=4))\n",
    "        print(torch.round(torch.tensor(recon_data), decimals=4))\n",
    "        print(torch.min(recon_data))\n",
    "        print(torch.max(recon_data))\n",
    "        loss, recon_loss, kl_div = loss_vae_with_kl_annealing(recon_data, real_data, mu, logvar, kl_weight)\n",
    "        epoch_recon_loss += recon_loss.item()\n",
    "        epoch_kl_divergence += kl_div.item()\n",
    "        loss.backward()\n",
    "              # Verificar si la pÃ©rdida es NaN\n",
    "        if torch.isnan(loss):\n",
    "            print(\"NaN detected!\")\n",
    "            break\n",
    "        torch.nn.utils.clip_grad_norm_(vae.parameters(), max_norm=1.0)\n",
    "        vae_optimizer.step()\n",
    "        # Rastrear gradientes y valores extremos\n",
    "        for name, param in vae.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                grad_max = torch.max(param.grad).item()\n",
    "                grad_min = torch.min(param.grad).item()\n",
    "                print(grad_max)\n",
    "                print(grad_min)\n",
    "                #if torch.isnan(grad_max) or torch.isnan(grad_min):\n",
    "                    #print(f'NaN encontrado en el gradiente de {name}')\n",
    "                #elif grad_max > threshold or grad_min < -threshold:\n",
    "                    #print(f'Gradiente extremo detectado en {name}: max {grad_max}, min {grad_min}')\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} | Total Loss: {loss.item()} | Recon Loss: {epoch_recon_loss/n_samples} | KL Div: {epoch_kl_divergence/n_samples}\")\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Calcular la diferencia de tiempo\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f\"El cÃ³digo tardÃ³ {elapsed_time:.5f} segundos en ejecutarse.\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        if(loss.item()<best_loss):\n",
    "            best_loss=loss.item()\n",
    "            print(\"Saved model\")\n",
    "            torch.save(vae.state_dict(), fnmodel)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c43b32-e348-4efb-b6b2-c854997a7a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fede/PyEnv/PB/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-14 10:32:26.915279: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-14 10:32:27.056749: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-14 10:32:27.056772: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-14 10:32:27.057456: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-14 10:32:27.123322: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-14 10:32:27.854035: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fnexpr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m sys\u001b[38;5;241m.\u001b[39msetrecursionlimit(\u001b[38;5;241m20000\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Cargamos los datos\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m expr_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mfnexpr\u001b[49m)\n\u001b[1;32m     22\u001b[0m meth_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fnmet)\n\u001b[1;32m     23\u001b[0m assig_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fnassig)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fnexpr' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import wasserstein_distance, ks_2samp\n",
    "import sys\n",
    "import umap\n",
    "sys.setrecursionlimit(20000)\n",
    "# Cargamos los datos\n",
    "expr_data = pd.read_csv(fnexpr)\n",
    "meth_data = pd.read_csv(fnmet)\n",
    "assig_data = pd.read_csv(fnassig)\n",
    "expr_data = expr_data.iloc[:, 1:]\n",
    "meth_data = meth_data.iloc[:, 1:]\n",
    "assig_data = assig_data.iloc[:, 2:]\n",
    "\n",
    "# Convertir todas las columnas a tipo float\n",
    "expr_data = expr_data.apply(pd.to_numeric, errors='coerce')\n",
    "meth_data = meth_data.apply(pd.to_numeric, errors='coerce')\n",
    "assig_data = assig_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Lidiar con valores NaN (si los hay). Pone 0 (CAMBIAR)\n",
    "#expr_data.fillna(0, inplace=True)\n",
    "#meth_data.fillna(0, inplace=True)\n",
    "#assig_data.fillna(0, inplace=True)\n",
    "\n",
    "expr_data = scaler.fit_transform(expr_data)\n",
    "meth_data = scaler.fit_transform(meth_data)\n",
    "assig_data = assig_data-1\n",
    "expr_data = pd.DataFrame(expr_data)\n",
    "meth_data = pd.DataFrame(meth_data)\n",
    "assig_data = pd.DataFrame(assig_data)\n",
    "\n",
    "# Combinamos los datos de expresiÃ³n gÃ©nica y metilaciÃ³n\n",
    "X_real = pd.concat([expr_data, meth_data], axis=1)\n",
    "\n",
    "# Generar datos de expresiÃ³n sintÃ©tica\n",
    "vae = VAE(combined_data.shape[1],ldim).to(device)\n",
    "vae.load_state_dict(torch.load(fnmodel))\n",
    "vae.eval()\n",
    "\n",
    "# FunciÃ³n para reparametrizaciÃ³n (para generar muestras del espacio latente)\n",
    "\n",
    "# Generar datos de expresiÃ³n sintÃ©tica\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(nsamp, ldim).to(device)\n",
    "    synthetic_expression = vae.decoder(z).to(device)\n",
    "    #synthetic_expression = torch.sigmoid(synthetic_expression)\n",
    "    #print(synthetic_expression)\n",
    "    expressions_list=synthetic_expression.detach().cpu().numpy().squeeze()\n",
    "\n",
    "X_gan = pd.DataFrame(expressions_list)\n",
    "#X = X.apply(pd.to_numeric, errors='coerce')\n",
    "y = X_gan.iloc[:, -1].values.astype(int)  \n",
    "\n",
    "X = X_gan.iloc[:, :-1]\n",
    "\n",
    "last_column = X_gan.columns[-1]\n",
    "X_gan = X_gan.drop(columns=[last_column])\n",
    "X_gan.columns = X_real.columns\n",
    "# Concatena los datos reales con los generados\n",
    "X_combined = np.vstack([X_real, X_gan])\n",
    "\n",
    "\n",
    "\n",
    "# Aplanar los datos para cÃ¡lculos estadÃ­sticos\n",
    "real_data_flattened = X_real.values.flatten()\n",
    "generated_data_flattened = X_gan.values.flatten()\n",
    "\n",
    "# Wasserstein Distance\n",
    "w_distance = wasserstein_distance(real_data_flattened, generated_data_flattened)\n",
    "\n",
    "# KS Test\n",
    "ks_statistic, ks_pvalue = ks_2samp(real_data_flattened, generated_data_flattened)\n",
    "\n",
    "print(f\"Wasserstein Distance: {w_distance}\")\n",
    "print(f\"KS Statistic: {ks_statistic}, P-Value: {ks_pvalue}\")\n",
    "\n",
    "# Suponiendo que X_real y X_gan son tus dos grupos de datos\n",
    "distancias_euclidianas = cdist(X_real, X_gan, metric='euclidean')\n",
    "\n",
    "# Calcular la distancia promedio\n",
    "distancia_promedio_euclidiana = np.mean(distancias_euclidianas)\n",
    "print(\"Distancia Euclidiana Promedio:\", distancia_promedio_euclidiana)\n",
    "\n",
    "# Calcula las matrices de correlaciÃ³n\n",
    "corr_real = X_real.corr()\n",
    "corr_gan = X_gan.corr()\n",
    "\n",
    "# Dibuja las matrices de correlaciÃ³n\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(corr_real, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix (Real Data)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(corr_gan, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix (Generated Data)')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calcula la matriz de diferencias\n",
    "corr_diff = corr_real - corr_gan\n",
    "\n",
    "# Dibuja la matriz de diferencias\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_diff, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Difference in Correlation Matrices')\n",
    "plt.show()\n",
    "\n",
    "# Etiquetas: 1 para real, 0 para generado\n",
    "y_real = [1] * X_real.shape[0]\n",
    "y_gan = [0] * X_gan.shape[0]\n",
    "\n",
    "# Combina los datos y las etiquetas\n",
    "#X_combined = pd.concat([X_real, X_gan], axis=0)\n",
    "y_combined = y_real + y_gan\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.3, random_state=42)\n",
    "\n",
    "# Inicializa y entrena el clasificador SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Realiza predicciones en el conjunto de prueba\n",
    "y_pred = svc.predict(X_test)\n",
    "# EvalÃºa el rendimiento del clasificador\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.savefig(filename+\"SVC1.jpg\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenamos el modelo SVC\n",
    "clf = SVC()\n",
    "unique_classes = np.unique(y_train)\n",
    "if len(unique_classes) > 1:\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predicciones\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # MÃ©tricas de clasificaciÃ³n\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Matriz de confusiÃ³n\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='g')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.savefig(filename+\"SVC2.jpg\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"SVC: Solo una clase\")\n",
    "\n",
    "\n",
    "\n",
    "# Clustering jerÃ¡rquico\n",
    "linked1 = linkage(X_real, method='ward')\n",
    "linked2 = linkage(X_gan, method='ward')\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked1, orientation='top', no_labels=True)\n",
    "plt.title(\"Dendrograma jerÃ¡rquico Real\")\n",
    "plt.savefig(filename+\"DJR.jpg\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked2, orientation='top', no_labels=True)\n",
    "plt.title(\"Dendrograma jerÃ¡rquico Generado\")\n",
    "plt.savefig(filename+\"DJG.jpg\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# K-Means\n",
    "k = 2\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "kmeans.fit(X_real)\n",
    "labels = kmeans.predict(X_real)\n",
    "centroids = kmeans.cluster_centers_\n",
    "X_array = X_real.values\n",
    "generated_data=X_gan.values\n",
    "plt.scatter(X_array[:, 0], X_array[:, 1], c=labels, s=50, cmap='viridis')\n",
    "plt.scatter(generated_data[:, 0], generated_data[:, 1], s=50, color='pink', label='Datos Generados')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.75)\n",
    "plt.savefig(filename+\"KNN.jpg\")\n",
    "plt.show()\n",
    "\n",
    "# t-SNE\n",
    "# Crea etiquetas para los datos (1 para reales, 0 para GAN)\n",
    "labels = np.concatenate([np.ones(X_real.shape[0]), np.zeros(X_gan.shape[0])])\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_combined)\n",
    "\n",
    "plt.scatter(X_tsne[labels==1, 0], X_tsne[labels==1, 1], c='blue', label='Real', s=3)\n",
    "plt.scatter(X_tsne[labels==0, 0], X_tsne[labels==0, 1], c='red', label='Generated', s=3)\n",
    "plt.legend()\n",
    "plt.title('t-SNE visualization')\n",
    "plt.savefig(filename+\"tsne.jpg\")\n",
    "plt.show()\n",
    "\n",
    "# Configurando y entrenando UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "X_umap = umap_model.fit_transform(X_combined)\n",
    "\n",
    "# Dibujando la visualizaciÃ³n\n",
    "plt.scatter(X_umap[labels==1, 0], X_umap[labels==1, 1], c='blue', label='Real', s=3)\n",
    "plt.scatter(X_umap[labels==0, 0], X_umap[labels==0, 1], c='red', label='Generated', s=3)\n",
    "plt.legend()\n",
    "plt.title('UMAP visualization')\n",
    "plt.savefig(filename+\"umap.jpg\")\n",
    "plt.show()\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_combined)\n",
    "\n",
    "# Dibujar el resultado\n",
    "plt.scatter(X_pca[labels==1, 0], X_pca[labels==1, 1], c='blue', label='Real', s=3)\n",
    "plt.scatter(X_pca[labels==0, 0], X_pca[labels==0, 1], c='red', label='Generated', s=3)\n",
    "plt.legend()\n",
    "plt.title('PCA visualization')\n",
    "plt.savefig(filename+\"pca.jpg\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#KDE\n",
    "column_names = X_real.columns.tolist()\n",
    "random_columns = random.sample(column_names, 20)\n",
    "for column_name in random_columns:\n",
    "    sns.kdeplot(X_real[column_name], label='Real',color='blue')\n",
    "    sns.kdeplot(X_gan[column_name], label='Generated',color='red')\n",
    "    plt.legend()\n",
    "    plt.title(f'Distribution for \"{column_name}\"')\n",
    "    plt.savefig(f\"{filename}kde-{column_name}.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8b7b5-c373-4a86-9b69-eb5ddebd998a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
