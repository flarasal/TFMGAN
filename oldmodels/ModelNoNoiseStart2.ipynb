{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefe2b6d-ee4c-44a3-b1f2-2dda2ca33fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade19a53-9154-49af-a8d1-6136ad278adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# Definir el generador y el discriminador\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.Sigmoid()\n",
    "                    \n",
    "            #nn.Linear(input_dim, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            #nn.ReLU(),\n",
    "            \n",
    "            #nn.Linear(512, 768),\n",
    "            #nn.BatchNorm1d(768),\n",
    "            #nn.ReLU(),\n",
    "            \n",
    "            #nn.Linear(768, 1024),\n",
    "            #nn.BatchNorm1d(1024),\n",
    "            #nn.ReLU(),\n",
    "\n",
    "            #nn.Linear(1024, 768),\n",
    "            #nn.BatchNorm1d(768),\n",
    "            #nn.ReLU(),\n",
    "            \n",
    "            #nn.Linear(768, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            #nn.ReLU(),\n",
    "            \n",
    "            #nn.Linear(512, output_dim),\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "            #nn.Linear(input_dim, 256),\n",
    "            #nn.BatchNorm1d(256),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(0.3),\n",
    "        \n",
    "            #nn.Linear(256, 128),\n",
    "            #nn.BatchNorm1d(128),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(0.3),\n",
    "            \n",
    "            #nn.Linear(128, 64),\n",
    "            #nn.BatchNorm1d(64),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(0.3),\n",
    "    \n",
    "            #nn.Linear(256, 1),\n",
    "            #nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        \n",
    "# Leer datos\n",
    "expression_data = pd.read_csv('exprTRAIN.csv')\n",
    "methylation_data = pd.read_csv('methylTRAIN.csv')\n",
    "assign_data = pd.read_csv('assignTRAIN.csv')\n",
    "\n",
    "expression_data = expression_data.iloc[:, 1:]\n",
    "methylation_data = methylation_data.iloc[:, 1:]\n",
    "assign_data = assign_data.iloc[:, 2:]\n",
    "\n",
    "# Convertir todas las columnas a tipo float\n",
    "expression_data = expression_data.apply(pd.to_numeric, errors='coerce')\n",
    "methylation_data = methylation_data.apply(pd.to_numeric, errors='coerce')\n",
    "assign_data = assign_data.apply(pd.to_numeric, errors='coerce')\n",
    "# Lidiar con valores NaN (si los hay). Pone 0(CAMBIAR)\n",
    "expression_data.fillna(0, inplace=True)\n",
    "methylation_data.fillna(0, inplace=True)\n",
    "assign_data.fillna(0, inplace=True)\n",
    "\n",
    "expression_data = expression_data.values\n",
    "methylation_data = methylation_data.values\n",
    "assign_data=assign_data.values\n",
    "# Asegurar que tienes el mismo número de muestras en ambos conjuntos de datos\n",
    "\n",
    "\n",
    "assert expression_data.shape[0] == methylation_data.shape[0], \"Los datos de expresión y metilación deben tener el mismo número de muestras.\"\n",
    "assert assign_data.shape[0] == methylation_data.shape[0], \"Los datos de asignación y metilación deben tener el mismo número de muestras.\"\n",
    "\n",
    "# Concatenar los datos\n",
    "#combined_data =torch.FloatTensor(np.hstack((expression_data, methylation_data,assign_data)))\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\"\n",
    "expression_data = torch.FloatTensor(expression_data).to(device)\n",
    "methylation_data = torch.FloatTensor(methylation_data).to(device)\n",
    "assign_data = torch.FloatTensor(assign_data).to(device)\n",
    "combined_data = torch.cat((expression_data,methylation_data,assign_data), 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86d3896-e768-4b62-ae06-ddf92e142812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo Generator tiene 144496 parámetros entrenables.\n",
      "El modelo Discriminator tiene 226817 parámetros entrenables.\n",
      "Epoch 100/10000 | Disc Loss: 0.6040832996368408 | Gen Loss: 133.62586975097656| Gan Loss: 1.8124116659164429| Mse Loss: 146.45941162109375\n",
      "El código tardó 47.65182 segundos en ejecutarse.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m fake_loss \u001b[38;5;241m=\u001b[39m criterion(fake_preds, fake_labels)\n\u001b[1;32m     40\u001b[0m disc_loss \u001b[38;5;241m=\u001b[39m real_loss \u001b[38;5;241m+\u001b[39m fake_loss\n\u001b[0;32m---> 41\u001b[0m \u001b[43mdisc_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m disc_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Entrenar generador\u001b[39;00m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modelos y optimizadores\n",
    "gen = Generator(expression_data.shape[1], methylation_data.shape[1]+assign_data.shape[1]).to(device)\n",
    "disc = Discriminator(expression_data.shape[1] + methylation_data.shape[1]+assign_data.shape[1]).to(device)\n",
    "print(f'El modelo Generator tiene {count_parameters(gen)} parámetros entrenables.')\n",
    "print(f'El modelo Discriminator tiene {count_parameters(disc)} parámetros entrenables.')\n",
    "gen_optimizer = optim.RMSprop(gen.parameters(), lr=0.0002)\n",
    "disc_optimizer = optim.RMSprop(disc.parameters(), lr=0.0002)\n",
    "criterion = nn.BCELoss()\n",
    "mse_criterion = nn.MSELoss(reduction='sum')\n",
    "# Entrenamiento\n",
    "n_samples = combined_data.size(0)\n",
    "batch_size = 64\n",
    "n_epochs = 10000\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    for idx in range(0, n_samples, batch_size):\n",
    "        real_data = combined_data[idx:idx+batch_size].to(device)\n",
    "        current_batch_size = real_data.size(0)\n",
    "        real_labels = torch.ones(current_batch_size, 1).to(device)\n",
    "\n",
    "        #noise = torch.randn(current_batch_size, 100).to(device)\n",
    "        noise = expression_data[idx:idx+batch_size]\n",
    "        \n",
    "        fake_methyl = gen(noise).to(device)\n",
    "        #fake_data = torch.cat((expression_data[idx:idx+batch_size],fake_methyl), 1)\n",
    "\n",
    "        fake_data = torch.cat((expression_data[idx:idx+batch_size],fake_methyl ), 1).to(device)\n",
    "\n",
    "        fake_labels = torch.zeros(current_batch_size, 1).to(device)\n",
    "        \n",
    "        # Entrenar discriminador\n",
    "        disc_optimizer.zero_grad()\n",
    "\n",
    "        real_preds = disc(real_data).to(device)\n",
    "        real_loss = criterion(real_preds, real_labels)\n",
    "        \n",
    "        fake_preds = disc(fake_data).to(device)\n",
    "        fake_loss = criterion(fake_preds, fake_labels)\n",
    "\n",
    "        disc_loss = real_loss + fake_loss\n",
    "        disc_loss.backward()\n",
    "        disc_optimizer.step()\n",
    "\n",
    "        # Entrenar generador\n",
    "        gen_optimizer.zero_grad()\n",
    "\n",
    "        #noise = torch.randn(current_batch_size, 100).to(device)\n",
    "        noise = expression_data[idx:idx+batch_size]\n",
    "        fake_methyl = gen(noise).to(device)\n",
    "        fake_data = torch.cat((expression_data[idx:idx+batch_size],fake_methyl ), 1).to(device)\n",
    "        fake_preds = disc(fake_data).to(device)\n",
    "\n",
    "\n",
    "        # Loss basado en la capacidad de engañar al discriminador\n",
    "        gan_loss = criterion(fake_preds, real_labels)\n",
    "\n",
    "        # MSE loss entre el metilación generado y el metilación real\n",
    "        mse_loss = mse_criterion(fake_methyl,  torch.cat((methylation_data[idx:idx+batch_size],assign_data[idx:idx+batch_size]),1).to(device))\n",
    "\n",
    "        # Combina ambos losses. El coeficiente 'alpha' permite ponderar la importancia relativa de cada loss.\n",
    "        alpha = 0.9\n",
    "        gen_loss = gan_loss + alpha * mse_loss\n",
    "\n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} | Disc Loss: {disc_loss.item()} | Gen Loss: {gen_loss.item()}| Gan Loss: {gan_loss.item()}| Mse Loss: {mse_loss.item()}\")\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calcular la diferencia de tiempo\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f\"El código tardó {elapsed_time:.5f} segundos en ejecutarse.\")\n",
    "        start_time = time.time()\n",
    "\n",
    "torch.save(gen.state_dict(), 'generator_model4.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be72300-c585-4101-b1f9-9ff6cb527c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Error cuadrático medio entre datos generados y reales: 0.20625117421150208\n",
      "Media: 0.3579321503639221\n",
      "Fila 1: MSE = 0.12975899875164032\n",
      "Fila 2: MSE = 0.3976130783557892\n",
      "Fila 3: MSE = 0.14586475491523743\n",
      "Fila 4: MSE = 0.1196136474609375\n",
      "Fila 5: MSE = 0.16281665861606598\n",
      "Fila 6: MSE = 0.14618311822414398\n",
      "Fila 7: MSE = 0.16538189351558685\n",
      "Fila 8: MSE = 0.14994896948337555\n",
      "Fila 9: MSE = 0.1513204574584961\n",
      "Fila 10: MSE = 0.1611705720424652\n",
      "Fila 11: MSE = 0.15778952836990356\n",
      "Fila 12: MSE = 0.14363645017147064\n",
      "Fila 13: MSE = 0.17841416597366333\n",
      "Fila 14: MSE = 0.16862589120864868\n",
      "Fila 15: MSE = 0.14946164190769196\n",
      "Fila 16: MSE = 0.15830308198928833\n",
      "Fila 17: MSE = 0.1867051124572754\n",
      "Fila 18: MSE = 0.1622389554977417\n",
      "Fila 19: MSE = 0.17763304710388184\n",
      "Fila 20: MSE = 0.12781864404678345\n",
      "Fila 21: MSE = 0.5329446196556091\n",
      "Fila 22: MSE = 0.16064424812793732\n",
      "Fila 23: MSE = 0.45325592160224915\n",
      "Fila 24: MSE = 0.15466512739658356\n",
      "Fila 25: MSE = 0.15345528721809387\n",
      "Fila 26: MSE = 0.16321437060832977\n",
      "Fila 27: MSE = 0.1801433563232422\n",
      "Fila 28: MSE = 0.14899928867816925\n",
      "Fila 29: MSE = 0.16318167746067047\n",
      "Fila 30: MSE = 0.15913549065589905\n",
      "Fila 31: MSE = 0.16366076469421387\n",
      "Fila 32: MSE = 0.20094452798366547\n",
      "Fila 33: MSE = 0.1431620866060257\n",
      "Fila 34: MSE = 0.42854318022727966\n",
      "Fila 35: MSE = 0.16573049128055573\n",
      "Fila 36: MSE = 0.17453250288963318\n",
      "Fila 37: MSE = 0.13408112525939941\n",
      "Fila 38: MSE = 0.4272059500217438\n",
      "Fila 39: MSE = 0.18624073266983032\n",
      "Fila 40: MSE = 0.10456004738807678\n",
      "Fila 41: MSE = 0.16818951070308685\n",
      "Fila 42: MSE = 0.15208272635936737\n",
      "Fila 43: MSE = 0.16378560662269592\n",
      "Fila 44: MSE = 0.16481786966323853\n",
      "Fila 45: MSE = 0.18443889915943146\n",
      "Fila 46: MSE = 0.16693934798240662\n",
      "Fila 47: MSE = 0.1441822499036789\n",
      "Fila 48: MSE = 0.17139698565006256\n",
      "Fila 49: MSE = 0.18862947821617126\n",
      "Fila 50: MSE = 0.17554731667041779\n",
      "Fila 51: MSE = 0.15033257007598877\n",
      "Fila 52: MSE = 0.1590830534696579\n",
      "Fila 53: MSE = 0.3353329300880432\n",
      "Fila 54: MSE = 0.16390568017959595\n",
      "Fila 55: MSE = 0.19598588347434998\n",
      "Fila 56: MSE = 0.14689037203788757\n",
      "Fila 57: MSE = 0.1669013798236847\n",
      "Fila 58: MSE = 0.16869065165519714\n",
      "Fila 59: MSE = 0.1776527762413025\n",
      "Fila 60: MSE = 0.13896708190441132\n",
      "Fila 61: MSE = 0.1308080106973648\n",
      "Fila 62: MSE = 0.14461666345596313\n",
      "Fila 63: MSE = 0.15936718881130219\n",
      "Fila 64: MSE = 0.12594270706176758\n",
      "Fila 65: MSE = 0.15596850216388702\n",
      "Fila 66: MSE = 0.42620593309402466\n",
      "Fila 67: MSE = 0.17005868256092072\n",
      "Fila 68: MSE = 0.12911875545978546\n",
      "Fila 69: MSE = 0.1660892218351364\n",
      "Fila 70: MSE = 0.3986133635044098\n",
      "Fila 71: MSE = 0.3343838155269623\n",
      "Fila 72: MSE = 0.4457637071609497\n",
      "Fila 73: MSE = 0.4901461601257324\n",
      "Fila 74: MSE = 0.37808820605278015\n",
      "Fila 75: MSE = 0.49463769793510437\n",
      "Fila 76: MSE = 0.1360299438238144\n",
      "Fila 77: MSE = 0.16454818844795227\n",
      "Fila 78: MSE = 0.15157602727413177\n",
      "Fila 79: MSE = 0.19342924654483795\n",
      "Fila 80: MSE = 0.15122747421264648\n",
      "Fila 81: MSE = 0.15972274541854858\n",
      "Fila 82: MSE = 0.17646723985671997\n",
      "Fila 83: MSE = 0.14532947540283203\n",
      "Fila 84: MSE = 0.4558477997779846\n",
      "Fila 85: MSE = 0.36404314637184143\n",
      "Fila 86: MSE = 0.15481795370578766\n",
      "Fila 87: MSE = 0.16823668777942657\n",
      "Fila 88: MSE = 0.31336140632629395\n",
      "Fila 89: MSE = 0.1257631629705429\n",
      "Fila 90: MSE = 0.37879329919815063\n",
      "Fila 91: MSE = 0.13845910131931305\n",
      "Fila 92: MSE = 0.13299143314361572\n",
      "Fila 93: MSE = 0.4860932528972626\n",
      "Fila 94: MSE = 0.13239414989948273\n",
      "Fila 95: MSE = 0.1445208191871643\n",
      "Fila 96: MSE = 0.1797974705696106\n",
      "Fila 97: MSE = 0.4982994794845581\n",
      "Fila 98: MSE = 0.13227973878383636\n",
      "Fila 99: MSE = 0.13695748150348663\n",
      "Fila 100: MSE = 0.15053260326385498\n",
      "Fila 101: MSE = 0.17252536118030548\n",
      "Fila 102: MSE = 0.4250164031982422\n",
      "Fila 103: MSE = 0.1567247062921524\n",
      "Fila 104: MSE = 0.15892377495765686\n",
      "Fila 105: MSE = 0.14571231603622437\n",
      "Fila 106: MSE = 0.14902643859386444\n",
      "Fila 107: MSE = 0.14504526555538177\n",
      "Fila 108: MSE = 0.13866719603538513\n",
      "Fila 109: MSE = 0.14290380477905273\n",
      "Fila 110: MSE = 0.1797080636024475\n",
      "Fila 111: MSE = 0.16125421226024628\n",
      "Fila 112: MSE = 0.1547822803258896\n",
      "Fila 113: MSE = 0.1575527787208557\n",
      "Fila 114: MSE = 0.1469959020614624\n",
      "Fila 115: MSE = 0.49627140164375305\n",
      "Fila 116: MSE = 0.15259073674678802\n",
      "Fila 117: MSE = 0.14877727627754211\n",
      "Fila 118: MSE = 0.13707081973552704\n",
      "Fila 119: MSE = 0.28147822618484497\n",
      "Fila 120: MSE = 0.47884589433670044\n",
      "Fila 121: MSE = 0.14787887036800385\n",
      "Fila 122: MSE = 0.14767512679100037\n",
      "Fila 123: MSE = 0.15692855417728424\n",
      "Fila 124: MSE = 0.16264532506465912\n",
      "Fila 125: MSE = 0.14469356834888458\n",
      "Fila 126: MSE = 0.13404525816440582\n",
      "Fila 127: MSE = 0.15959662199020386\n",
      "Fila 128: MSE = 0.13568298518657684\n",
      "Fila 129: MSE = 0.14687281847000122\n",
      "Fila 130: MSE = 0.1259537786245346\n",
      "Fila 131: MSE = 0.15444865822792053\n",
      "Fila 132: MSE = 0.5440664887428284\n",
      "Fila 133: MSE = 0.13859178125858307\n",
      "Fila 134: MSE = 0.42582231760025024\n",
      "Fila 135: MSE = 0.1915377825498581\n",
      "Fila 136: MSE = 0.16586251556873322\n",
      "Fila 137: MSE = 0.1733899861574173\n",
      "Fila 138: MSE = 0.13294295966625214\n",
      "Fila 139: MSE = 0.14357596635818481\n",
      "Fila 140: MSE = 0.37602582573890686\n",
      "Fila 141: MSE = 0.3613802194595337\n",
      "Fila 142: MSE = 0.15471631288528442\n",
      "Fila 143: MSE = 0.1725245863199234\n",
      "Fila 144: MSE = 0.19857512414455414\n",
      "Fila 145: MSE = 0.41660076379776\n",
      "Fila 146: MSE = 0.1215759813785553\n",
      "Fila 147: MSE = 0.1684938669204712\n",
      "Fila 148: MSE = 0.16508428752422333\n",
      "Fila 149: MSE = 0.14439517259597778\n",
      "Fila 150: MSE = 0.41511070728302\n",
      "Fila 151: MSE = 0.4740999937057495\n",
      "Fila 152: MSE = 0.14038807153701782\n",
      "Fila 153: MSE = 0.3532521724700928\n",
      "Fila 154: MSE = 0.14930374920368195\n",
      "Fila 155: MSE = 0.17927752435207367\n",
      "Fila 156: MSE = 0.17988187074661255\n",
      "Fila 157: MSE = 0.47330909967422485\n",
      "Fila 158: MSE = 0.13933275640010834\n",
      "Fila 159: MSE = 0.16380217671394348\n",
      "Fila 160: MSE = 0.4017656743526459\n",
      "Fila 161: MSE = 0.16182072460651398\n",
      "Fila 162: MSE = 0.1546495109796524\n",
      "Fila 163: MSE = 0.16856005787849426\n",
      "Fila 164: MSE = 0.1486942023038864\n",
      "Fila 165: MSE = 0.17356827855110168\n",
      "Fila 166: MSE = 0.1555422693490982\n",
      "Fila 167: MSE = 0.14514335989952087\n",
      "Fila 168: MSE = 0.16604840755462646\n",
      "Fila 169: MSE = 0.16902495920658112\n",
      "Fila 170: MSE = 0.1407833993434906\n",
      "Fila 171: MSE = 0.1477106362581253\n",
      "Fila 172: MSE = 0.11348477751016617\n",
      "Fila 173: MSE = 0.1622079610824585\n",
      "Fila 174: MSE = 0.16086384654045105\n",
      "Fila 175: MSE = 0.13803908228874207\n",
      "Fila 176: MSE = 0.13758109509944916\n",
      "Fila 177: MSE = 0.16604790091514587\n",
      "Fila 178: MSE = 0.15334492921829224\n",
      "Fila 179: MSE = 0.17352229356765747\n",
      "Fila 180: MSE = 0.17591489851474762\n",
      "Fila 181: MSE = 0.14560340344905853\n",
      "Fila 182: MSE = 0.12928250432014465\n",
      "Fila 183: MSE = 0.4303780794143677\n",
      "Fila 184: MSE = 0.17946480214595795\n",
      "Fila 185: MSE = 0.1652597337961197\n",
      "Fila 186: MSE = 0.12624786794185638\n",
      "Fila 187: MSE = 0.1853376030921936\n",
      "Fila 188: MSE = 0.18386860191822052\n",
      "Fila 189: MSE = 0.13694961369037628\n",
      "Fila 190: MSE = 0.15662093460559845\n",
      "Fila 191: MSE = 0.17660504579544067\n",
      "Fila 192: MSE = 0.16579003632068634\n",
      "Fila 193: MSE = 0.4468701481819153\n",
      "Fila 194: MSE = 0.13375645875930786\n",
      "Fila 195: MSE = 0.16851063072681427\n",
      "Fila 196: MSE = 0.1517292559146881\n",
      "Fila 197: MSE = 0.32470056414604187\n",
      "Fila 198: MSE = 0.15505056083202362\n",
      "Fila 199: MSE = 0.12042887508869171\n",
      "Fila 200: MSE = 0.157339945435524\n",
      "Fila 201: MSE = 0.3941399157047272\n",
      "Fila 202: MSE = 0.16422145068645477\n",
      "Fila 203: MSE = 0.15974190831184387\n",
      "Fila 204: MSE = 0.16602733731269836\n",
      "Fila 205: MSE = 0.1566508412361145\n",
      "Fila 206: MSE = 0.12992943823337555\n",
      "Fila 207: MSE = 0.13084474205970764\n",
      "Fila 208: MSE = 0.168024942278862\n",
      "Fila 209: MSE = 0.14847995340824127\n",
      "Fila 210: MSE = 0.11388405412435532\n",
      "Fila 211: MSE = 0.1840221881866455\n",
      "Fila 212: MSE = 0.13549888134002686\n",
      "Fila 213: MSE = 0.15953843295574188\n",
      "Fila 214: MSE = 0.12662489712238312\n",
      "Fila 215: MSE = 0.38062727451324463\n",
      "Fila 216: MSE = 0.1301024854183197\n",
      "Fila 217: MSE = 0.12244033813476562\n",
      "Fila 218: MSE = 0.1519581526517868\n",
      "Fila 219: MSE = 0.18789324164390564\n",
      "Fila 220: MSE = 0.14782105386257172\n",
      "Fila 221: MSE = 0.16007323563098907\n",
      "Fila 222: MSE = 0.15887762606143951\n",
      "Fila 223: MSE = 0.18602369725704193\n",
      "Fila 224: MSE = 0.19859422743320465\n",
      "Fila 225: MSE = 0.13734330236911774\n",
      "Fila 226: MSE = 0.1556241810321808\n",
      "Fila 227: MSE = 0.18157778680324554\n",
      "Fila 228: MSE = 0.16524562239646912\n",
      "Fila 229: MSE = 0.11092257499694824\n",
      "Fila 230: MSE = 0.14731095731258392\n",
      "Fila 231: MSE = 0.16221144795417786\n",
      "Fila 232: MSE = 0.15100015699863434\n",
      "Fila 233: MSE = 0.16842086613178253\n",
      "Fila 234: MSE = 0.19563567638397217\n",
      "Fila 235: MSE = 0.18211200833320618\n",
      "Fila 236: MSE = 0.5002567768096924\n",
      "Fila 237: MSE = 0.15840859711170197\n",
      "Fila 238: MSE = 0.13890139758586884\n",
      "Fila 239: MSE = 0.16547833383083344\n",
      "Fila 240: MSE = 0.1326388269662857\n",
      "Fila 241: MSE = 0.41703590750694275\n",
      "Fila 242: MSE = 0.15929900109767914\n",
      "Fila 243: MSE = 0.1558552384376526\n",
      "Fila 244: MSE = 0.42472657561302185\n",
      "Fila 245: MSE = 0.13640965521335602\n",
      "Fila 246: MSE = 0.16045355796813965\n",
      "Fila 247: MSE = 0.3258753716945648\n",
      "Fila 248: MSE = 0.12807093560695648\n",
      "Fila 249: MSE = 0.1586470752954483\n",
      "Fila 250: MSE = 0.43517637252807617\n",
      "Fila 251: MSE = 0.18135319650173187\n",
      "Fila 252: MSE = 0.12330833822488785\n",
      "Fila 253: MSE = 0.17055806517601013\n",
      "Fila 254: MSE = 0.13652090728282928\n",
      "Fila 255: MSE = 0.10763587057590485\n",
      "Fila 256: MSE = 0.42712005972862244\n",
      "Fila 257: MSE = 0.20268963277339935\n",
      "Fila 258: MSE = 0.11297920346260071\n",
      "Fila 259: MSE = 0.37160736322402954\n",
      "Fila 260: MSE = 0.14779062569141388\n",
      "Fila 261: MSE = 0.19606108963489532\n",
      "Fila 262: MSE = 0.15532638132572174\n",
      "Fila 263: MSE = 0.41510847210884094\n",
      "Fila 264: MSE = 0.3569197654724121\n",
      "Fila 265: MSE = 0.5244225859642029\n",
      "Fila 266: MSE = 0.39272910356521606\n",
      "Fila 267: MSE = 0.1668769270181656\n",
      "Fila 268: MSE = 0.17223064601421356\n",
      "Fila 269: MSE = 0.19461242854595184\n",
      "Fila 270: MSE = 0.5053537487983704\n",
      "Fila 271: MSE = 0.17543324828147888\n",
      "Fila 272: MSE = 0.3202977776527405\n",
      "Fila 273: MSE = 0.16880859434604645\n",
      "Fila 274: MSE = 0.15232889354228973\n",
      "Fila 275: MSE = 0.15730537474155426\n",
      "Fila 276: MSE = 0.12080337852239609\n",
      "Fila 277: MSE = 0.170060396194458\n",
      "Fila 278: MSE = 0.39795008301734924\n",
      "Fila 279: MSE = 0.1800031065940857\n",
      "Fila 280: MSE = 0.17324323952198029\n",
      "Fila 281: MSE = 0.1502094268798828\n",
      "Fila 282: MSE = 0.17943879961967468\n",
      "Fila 283: MSE = 0.10679987072944641\n",
      "Fila 284: MSE = 0.1220121830701828\n",
      "Fila 285: MSE = 0.16516731679439545\n",
      "Fila 286: MSE = 0.3964174687862396\n",
      "Fila 287: MSE = 0.18882130086421967\n",
      "Fila 288: MSE = 0.14237838983535767\n",
      "Fila 289: MSE = 0.36014324426651\n",
      "Fila 290: MSE = 0.16077253222465515\n",
      "Fila 291: MSE = 0.12577614188194275\n",
      "Fila 292: MSE = 0.15975803136825562\n",
      "Fila 293: MSE = 0.14887499809265137\n",
      "Fila 294: MSE = 0.3543514311313629\n",
      "Fila 295: MSE = 0.4018857479095459\n",
      "Fila 296: MSE = 0.39598551392555237\n",
      "Fila 297: MSE = 0.40923869609832764\n",
      "Fila 298: MSE = 0.1750558316707611\n",
      "Fila 299: MSE = 0.15893760323524475\n",
      "Fila 300: MSE = 0.15112467110157013\n",
      "Fila 301: MSE = 0.16050253808498383\n",
      "Fila 302: MSE = 0.12531279027462006\n",
      "Fila 303: MSE = 0.1551990956068039\n",
      "Fila 304: MSE = 0.47285959124565125\n",
      "Fila 305: MSE = 0.127772256731987\n",
      "Fila 306: MSE = 0.1381351202726364\n",
      "Fila 307: MSE = 0.16933952271938324\n",
      "Fila 308: MSE = 0.14491717517375946\n",
      "Fila 309: MSE = 0.1577192097902298\n",
      "Fila 310: MSE = 0.12857721745967865\n",
      "Fila 311: MSE = 0.15043902397155762\n",
      "Fila 312: MSE = 0.3230028748512268\n",
      "Fila 313: MSE = 0.2062155306339264\n",
      "Fila 314: MSE = 0.5616992712020874\n",
      "Fila 315: MSE = 0.13468089699745178\n",
      "Fila 316: MSE = 0.1495685875415802\n",
      "Fila 317: MSE = 0.12111391127109528\n",
      "Fila 318: MSE = 0.17057041823863983\n",
      "Fila 319: MSE = 0.169651061296463\n",
      "Fila 320: MSE = 0.15128210186958313\n",
      "Fila 321: MSE = 0.15140880644321442\n",
      "Fila 322: MSE = 0.14737069606781006\n",
      "Fila 323: MSE = 0.4390782415866852\n",
      "Fila 324: MSE = 0.3975718319416046\n",
      "Fila 325: MSE = 0.16081248223781586\n",
      "Fila 326: MSE = 0.14654284715652466\n",
      "Fila 327: MSE = 0.13979093730449677\n",
      "Fila 328: MSE = 0.15025123953819275\n",
      "Fila 329: MSE = 0.40997573733329773\n",
      "Fila 330: MSE = 0.15449835360050201\n",
      "Fila 331: MSE = 0.42364224791526794\n",
      "Fila 332: MSE = 0.39739716053009033\n",
      "Fila 333: MSE = 0.4172838032245636\n",
      "Fila 334: MSE = 0.1466810256242752\n",
      "Fila 335: MSE = 0.15059655904769897\n",
      "Fila 336: MSE = 0.1530505269765854\n",
      "Fila 337: MSE = 0.1224919855594635\n",
      "Fila 338: MSE = 0.14058221876621246\n",
      "Fila 339: MSE = 0.16458973288536072\n",
      "Fila 340: MSE = 0.1438981592655182\n",
      "Fila 341: MSE = 0.15671254694461823\n",
      "Fila 342: MSE = 0.14460164308547974\n",
      "Fila 343: MSE = 0.18988677859306335\n",
      "Fila 344: MSE = 0.14940471947193146\n",
      "Fila 345: MSE = 0.14778690040111542\n",
      "Fila 346: MSE = 0.5069336891174316\n",
      "Fila 347: MSE = 0.1599101722240448\n",
      "Fila 348: MSE = 0.14244766533374786\n",
      "Fila 349: MSE = 0.17587855458259583\n",
      "Fila 350: MSE = 0.19451814889907837\n",
      "Fila 351: MSE = 0.13880521059036255\n",
      "Fila 352: MSE = 0.18497338891029358\n",
      "Fila 353: MSE = 0.16814912855625153\n",
      "Fila 354: MSE = 0.19738616049289703\n",
      "Fila 355: MSE = 0.446588933467865\n",
      "Fila 356: MSE = 0.14086101949214935\n",
      "Fila 357: MSE = 0.3828471004962921\n",
      "Fila 358: MSE = 0.15510517358779907\n",
      "Fila 359: MSE = 0.11020644009113312\n",
      "Fila 360: MSE = 0.1618034839630127\n",
      "Fila 361: MSE = 0.14280052483081818\n",
      "Fila 362: MSE = 0.428884357213974\n",
      "Fila 363: MSE = 0.4452430009841919\n",
      "Fila 364: MSE = 0.15469615161418915\n",
      "Fila 365: MSE = 0.13594700396060944\n",
      "Fila 366: MSE = 0.15356700122356415\n",
      "Fila 367: MSE = 0.13306955993175507\n",
      "Fila 368: MSE = 0.15499652922153473\n",
      "Fila 369: MSE = 0.3793697953224182\n",
      "Fila 370: MSE = 0.13623620569705963\n",
      "Fila 371: MSE = 0.44638586044311523\n",
      "Fila 372: MSE = 0.15823079645633698\n",
      "Fila 373: MSE = 0.15494383871555328\n",
      "Fila 374: MSE = 0.16109946370124817\n",
      "Fila 375: MSE = 0.41154858469963074\n",
      "Fila 376: MSE = 0.16865624487400055\n",
      "Fila 377: MSE = 0.4024249315261841\n",
      "Fila 378: MSE = 0.15048690140247345\n",
      "Fila 379: MSE = 0.14376921951770782\n",
      "Fila 380: MSE = 0.16769878566265106\n",
      "Fila 381: MSE = 0.14455285668373108\n",
      "Fila 382: MSE = 0.1295614242553711\n",
      "Fila 383: MSE = 0.14463311433792114\n",
      "Fila 384: MSE = 0.17517554759979248\n",
      "Fila 385: MSE = 0.17838014662265778\n",
      "Fila 386: MSE = 0.4300735294818878\n",
      "Fila 387: MSE = 0.13720166683197021\n",
      "Fila 388: MSE = 0.15398073196411133\n",
      "Fila 389: MSE = 0.15450003743171692\n",
      "Fila 390: MSE = 0.16350899636745453\n",
      "Fila 391: MSE = 0.10112966597080231\n",
      "Fila 392: MSE = 0.15882515907287598\n",
      "Fila 393: MSE = 0.1651112586259842\n",
      "Fila 394: MSE = 0.1618635207414627\n",
      "Fila 395: MSE = 0.16510312259197235\n",
      "Fila 396: MSE = 0.1571253091096878\n",
      "Fila 397: MSE = 0.1274709701538086\n",
      "Fila 398: MSE = 0.3736632168292999\n",
      "Fila 399: MSE = 0.1383741796016693\n",
      "Fila 400: MSE = 0.16430139541625977\n",
      "Fila 401: MSE = 0.11414080113172531\n",
      "Fila 402: MSE = 0.39022552967071533\n",
      "Fila 403: MSE = 0.16280461847782135\n",
      "Fila 404: MSE = 0.4169543385505676\n",
      "Fila 405: MSE = 0.16546805202960968\n",
      "Fila 406: MSE = 0.11155887693166733\n",
      "Fila 407: MSE = 0.19055768847465515\n",
      "Fila 408: MSE = 0.13763205707073212\n",
      "Fila 409: MSE = 0.17933833599090576\n",
      "Fila 410: MSE = 0.15262962877750397\n",
      "Fila 411: MSE = 0.15234166383743286\n",
      "Fila 412: MSE = 0.12135756760835648\n",
      "Fila 413: MSE = 0.41498005390167236\n",
      "Fila 414: MSE = 0.39314424991607666\n",
      "Fila 415: MSE = 0.1476803719997406\n",
      "Fila 416: MSE = 0.3440331816673279\n",
      "Fila 417: MSE = 0.13123340904712677\n",
      "Fila 418: MSE = 0.4951225817203522\n",
      "Fila 419: MSE = 0.18158173561096191\n",
      "Fila 420: MSE = 0.1698269248008728\n",
      "Fila 421: MSE = 0.13156799972057343\n",
      "Fila 422: MSE = 0.400014728307724\n",
      "Fila 423: MSE = 0.1445208489894867\n",
      "Fila 424: MSE = 0.44347307085990906\n",
      "Fila 425: MSE = 0.1608821451663971\n",
      "Fila 426: MSE = 0.13667814433574677\n",
      "Fila 427: MSE = 0.18836751580238342\n",
      "Fila 428: MSE = 0.1182766705751419\n",
      "Fila 429: MSE = 0.1443769484758377\n",
      "Fila 430: MSE = 0.15355831384658813\n",
      "Fila 431: MSE = 0.13685572147369385\n",
      "Fila 432: MSE = 0.14516578614711761\n",
      "Fila 433: MSE = 0.1641826331615448\n",
      "Fila 434: MSE = 0.11499062925577164\n",
      "Fila 435: MSE = 0.47020232677459717\n",
      "Fila 436: MSE = 0.18577298521995544\n",
      "Fila 437: MSE = 0.15708938241004944\n",
      "Fila 438: MSE = 0.13443247973918915\n",
      "Fila 439: MSE = 0.10455390065908432\n",
      "Fila 440: MSE = 0.13981804251670837\n",
      "Fila 441: MSE = 0.16229002177715302\n",
      "Fila 442: MSE = 0.18478327989578247\n",
      "Fila 443: MSE = 0.12892256677150726\n",
      "Fila 444: MSE = 0.31648892164230347\n",
      "Fila 445: MSE = 0.42320388555526733\n",
      "Fila 446: MSE = 0.4723478853702545\n",
      "Fila 447: MSE = 0.15084154903888702\n",
      "Fila 448: MSE = 0.1365239918231964\n",
      "Fila 449: MSE = 0.15852276980876923\n",
      "Fila 450: MSE = 0.14498630166053772\n",
      "Fila 451: MSE = 0.16748347878456116\n",
      "Fila 452: MSE = 0.1467006504535675\n",
      "Fila 453: MSE = 0.17575028538703918\n",
      "Fila 454: MSE = 0.17219187319278717\n",
      "Fila 455: MSE = 0.37267833948135376\n",
      "Fila 456: MSE = 0.13285335898399353\n",
      "Fila 457: MSE = 0.4027390778064728\n",
      "Fila 458: MSE = 0.15962722897529602\n",
      "Fila 459: MSE = 0.39318540692329407\n",
      "Fila 460: MSE = 0.37643951177597046\n",
      "Fila 461: MSE = 0.17300954461097717\n",
      "Fila 462: MSE = 0.17159922420978546\n",
      "Fila 463: MSE = 0.14348483085632324\n",
      "Fila 464: MSE = 0.1484614908695221\n",
      "Fila 465: MSE = 0.4793233871459961\n",
      "Fila 466: MSE = 0.30592289566993713\n",
      "Fila 467: MSE = 0.1495068371295929\n",
      "Fila 468: MSE = 0.1803337037563324\n",
      "Fila 469: MSE = 0.15813054144382477\n",
      "Fila 470: MSE = 0.3607172966003418\n",
      "Fila 471: MSE = 0.1600596159696579\n",
      "Fila 472: MSE = 0.17580260336399078\n",
      "Fila 473: MSE = 0.17029298841953278\n",
      "Fila 474: MSE = 0.1840965896844864\n",
      "Fila 475: MSE = 0.3682295083999634\n",
      "Fila 476: MSE = 0.17039212584495544\n",
      "Fila 477: MSE = 0.18963801860809326\n",
      "Fila 478: MSE = 0.12118540704250336\n",
      "Fila 479: MSE = 0.17035309970378876\n",
      "Fila 480: MSE = 0.16404016315937042\n",
      "Fila 481: MSE = 0.15758909285068512\n",
      "Fila 482: MSE = 0.1773223727941513\n",
      "Fila 483: MSE = 0.15235786139965057\n",
      "Fila 484: MSE = 0.15317398309707642\n",
      "Fila 485: MSE = 0.12894460558891296\n",
      "Fila 486: MSE = 0.16789677739143372\n",
      "Fila 487: MSE = 0.16133062541484833\n",
      "Fila 488: MSE = 0.13281555473804474\n",
      "Fila 489: MSE = 0.1493585854768753\n",
      "Fila 490: MSE = 0.17712931334972382\n",
      "Fila 491: MSE = 0.15457113087177277\n",
      "Fila 492: MSE = 0.1271044760942459\n",
      "Fila 493: MSE = 0.11247390508651733\n",
      "Fila 494: MSE = 0.1537434309720993\n",
      "Fila 495: MSE = 0.1391834318637848\n",
      "Fila 496: MSE = 0.16457930207252502\n",
      "Fila 497: MSE = 0.20935523509979248\n",
      "Fila 498: MSE = 0.13416029512882233\n",
      "Fila 499: MSE = 0.26301309466362\n",
      "Fila 500: MSE = 0.3907236158847809\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.nn.functional import mse_loss\n",
    "\n",
    "# Leer datos\n",
    "expression_data2 = pd.read_csv('exprTEST.csv')\n",
    "methylation_data2 = pd.read_csv('methylTEST.csv')\n",
    "assign_data2 = pd.read_csv('assignTEST.csv')\n",
    "\n",
    "expression_data2 = expression_data2.iloc[:, 1:]\n",
    "methylation_data2 = methylation_data2.iloc[:, 1:]\n",
    "assign_data2 = assign_data2.iloc[:, 2:]\n",
    "\n",
    "# Convertir todas las columnas a tipo float\n",
    "expression_data2 = expression_data2.apply(pd.to_numeric, errors='coerce')\n",
    "methylation_data2 = methylation_data2.apply(pd.to_numeric, errors='coerce')\n",
    "assign_data2 = assign_data2.apply(pd.to_numeric, errors='coerce')\n",
    "# Lidiar con valores NaN (si los hay). Pone 0(CAMBIAR)\n",
    "expression_data2.fillna(0, inplace=True)\n",
    "methylation_data2.fillna(0, inplace=True)\n",
    "assign_data2.fillna(0, inplace=True)\n",
    "\n",
    "expression_data2 = expression_data2.values\n",
    "methylation_data2 = methylation_data2.values\n",
    "assign_data2=assign_data2.values\n",
    "# Asegurar que tienes el mismo número de muestras en ambos conjuntos de datos\n",
    "\n",
    "\n",
    "assert expression_data2.shape[0] == methylation_data2.shape[0], \"Los datos de expresión y metilación deben tener el mismo número de muestras.\"\n",
    "assert assign_data2.shape[0] == methylation_data2.shape[0], \"Los datos de asignación y metilación deben tener el mismo número de muestras.\"\n",
    "\n",
    "# Concatenar los datos\n",
    "#combined_data =torch.FloatTensor(np.hstack((expression_data, methylation_data,assign_data)))\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\"\n",
    "expression_data2 = torch.FloatTensor(expression_data2).to(device)\n",
    "methylation_data2 = torch.FloatTensor(methylation_data2).to(device)\n",
    "assign_data2 = torch.FloatTensor(assign_data2).to(device)\n",
    "combined_data2= torch.cat((expression_data2,methylation_data2,assign_data2), 1).to(device)\n",
    "# Carga del modelo previamente entrenado\n",
    "gen = Generator(expression_data2.shape[1], methylation_data2.shape[1]+assign_data2.shape[1])\n",
    "gen.load_state_dict(torch.load('generator_model4.pth'))\n",
    "gen.eval()\n",
    "gen.to(device)\n",
    "\n",
    "# Pasar todos los datos de expr.csv a través del generador\n",
    "with torch.no_grad():\n",
    "    generated_methyl = gen(expression_data2)\n",
    "\n",
    "# Asegúrate de que los datos generados y los datos reales estén en la misma forma\n",
    "generated_methyl = generated_methyl.cpu().numpy()\n",
    "\n",
    "# Aquí estamos asumiendo que la primera parte de la salida generada corresponde a methyl.csv\n",
    "# Si tu salida generada incluye más datos además de methyl.csv, necesitas ajustar esto\n",
    "generated_methyl_data = generated_methyl[:, :methylation_data2.shape[1]]\n",
    "\n",
    "# Calcula el error cuadrático medio entre los datos generados y los reales\n",
    "mse = mean_squared_error(methylation_data2.cpu().numpy(), generated_methyl_data)\n",
    "print(f\"Error cuadrático medio entre datos generados y reales: {mse}\")\n",
    "print(f\"Media: {methylation_data2.mean()}\")\n",
    "# Si el MSE es bajo, significa que los datos generados y los datos reales son muy similares.\n",
    "\n",
    "individual_mse_errors = []\n",
    "\n",
    "# Procesar datos\n",
    "with torch.no_grad():\n",
    "    for i in range(expression_data2.shape[0]):\n",
    "        input_expr = expression_data2[i].unsqueeze(0)  # Añadir dimensión de batch\n",
    "        real_output = torch.cat([methylation_data2[i], assign_data2[i]]).unsqueeze(0)  # Añadir dimensión de batch\n",
    "        generated_output = gen(input_expr)\n",
    "        \n",
    "        error = mse_loss(generated_output, real_output)\n",
    "        #print(generated_output)\n",
    "        #print(real_output)\n",
    "        individual_mse_errors.append(error.item())\n",
    "\n",
    "# Si deseas, puedes imprimir el error MSE para cada fila\n",
    "for i, error in enumerate(individual_mse_errors):\n",
    "    print(f\"Fila {i + 1}: MSE = {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4389ef-27fa-4d77-b5cb-ac1662916c58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Entrenamos el modelo SVC\u001b[39;00m\n\u001b[1;32m     29\u001b[0m clf \u001b[38;5;241m=\u001b[39m SVC()\n\u001b[0;32m---> 30\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Predicciones\u001b[39;00m\n\u001b[1;32m     33\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/sklearn/svm/_base.py:199\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    191\u001b[0m         X,\n\u001b[1;32m    192\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m     )\n\u001b[0;32m--> 199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[1;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m    203\u001b[0m )\n\u001b[1;32m    204\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/sklearn/svm/_base.py:747\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 747\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    748\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of classes has to be greater than one; got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m class\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    750\u001b[0m     )\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Generar datos de expresión sintética\n",
    "gen2 = Generator(expression_data.shape[1], methylation_data.shape[1]+assign_data.shape[1]).to(device)\n",
    "gen2.load_state_dict(torch.load('generator_model2.pth'))\n",
    "gen2.eval()\n",
    "expressions_list = []\n",
    "for i in range(100000):\n",
    "    noise = torch.randn(1, expression_data.shape[1]).to(device)\n",
    "    synthetic_expression = gen2(noise).to(device)\n",
    "    #print(synthetic_expression)\n",
    "    expressions_list.append(synthetic_expression.detach().cpu().numpy().squeeze())\n",
    "\n",
    "X = pd.DataFrame(expressions_list)\n",
    "#X = X.apply(pd.to_numeric, errors='coerce')\n",
    "y = X.iloc[:, -1].values.astype(int)  # Suponiendo que la asignación está en la primera columna\n",
    "\n",
    "X = X.iloc[:, :-1]\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenamos el modelo SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Métricas de clasificación\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a54d7865-fa40-496c-944d-a230c3a87b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00     23934\n",
      "           2       1.00      1.00      1.00      6066\n",
      "\n",
      "    accuracy                           1.00     30000\n",
      "   macro avg       1.00      1.00      1.00     30000\n",
      "weighted avg       1.00      1.00      1.00     30000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargamos los datos\n",
    "expr_data = pd.read_csv('exprMID.csv')\n",
    "meth_data = pd.read_csv('methylMID.csv')\n",
    "assig_data = pd.read_csv('assignMID.csv')\n",
    "expr_data = expr_data.iloc[:, 1:]\n",
    "meth_data = meth_data.iloc[:, 1:]\n",
    "assig_data = assig_data.iloc[:, 2:]\n",
    "\n",
    "# Convertir todas las columnas a tipo float\n",
    "expr_data = expr_data.apply(pd.to_numeric, errors='coerce')\n",
    "meth_data = meth_data.apply(pd.to_numeric, errors='coerce')\n",
    "assig_data = assig_data.apply(pd.to_numeric, errors='coerce')\n",
    "# Lidiar con valores NaN (si los hay). Pone 0(CAMBIAR)\n",
    "expr_data.fillna(0, inplace=True)\n",
    "meth_data.fillna(0, inplace=True)\n",
    "assig_data.fillna(0, inplace=True)\n",
    "# Aseguramos que las dimensiones coincidan\n",
    "assert expr_data.shape[0] == meth_data.shape[0] == assig_data.shape[0], \"Las dimensiones de los archivos no coinciden\"\n",
    "\n",
    "# Combinamos los datos de expresión génica y metilación\n",
    "X = pd.concat([expr_data, meth_data], axis=1)\n",
    "y = assig_data.iloc[:, 0].values  # Suponiendo que la asignación está en la primera columna\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenamos el modelo SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Métricas de clasificación\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4684f20f-50aa-4729-b7f8-fa924b20592a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00     23934\n",
      "           2       1.00      1.00      1.00      6066\n",
      "\n",
      "    accuracy                           1.00     30000\n",
      "   macro avg       1.00      1.00      1.00     30000\n",
      "weighted avg       1.00      1.00      1.00     30000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargamos los datos\n",
    "expr_data = pd.read_csv('exprMID.csv')\n",
    "meth_data = pd.read_csv('methylMID.csv')\n",
    "assig_data = pd.read_csv('assignMID.csv')\n",
    "expr_data = expr_data.iloc[:, 1:]\n",
    "meth_data = meth_data.iloc[:, 1:]\n",
    "assig_data = assig_data.iloc[:, 2:]\n",
    "\n",
    "# Convertir todas las columnas a tipo float\n",
    "expr_data = expr_data.apply(pd.to_numeric, errors='coerce')\n",
    "meth_data = meth_data.apply(pd.to_numeric, errors='coerce')\n",
    "assig_data = assig_data.apply(pd.to_numeric, errors='coerce')\n",
    "# Lidiar con valores NaN (si los hay). Pone 0(CAMBIAR)\n",
    "expr_data.fillna(0, inplace=True)\n",
    "meth_data.fillna(0, inplace=True)\n",
    "assig_data.fillna(0, inplace=True)\n",
    "# Aseguramos que las dimensiones coincidan\n",
    "assert expr_data.shape[0] == meth_data.shape[0] == assig_data.shape[0], \"Las dimensiones de los archivos no coinciden\"\n",
    "\n",
    "# Combinamos los datos de expresión génica y metilación\n",
    "X = meth_data\n",
    "y = assig_data.iloc[:, 0].values  # Suponiendo que la asignación está en la primera columna\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenamos el modelo SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Métricas de clasificación\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8b7b5-c373-4a86-9b69-eb5ddebd998a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
