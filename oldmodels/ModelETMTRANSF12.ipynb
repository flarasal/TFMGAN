{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefe2b6d-ee4c-44a3-b1f2-2dda2ca33fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade19a53-9154-49af-a8d1-6136ad278adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from torch.utils.data import TensorDataset,DataLoader, random_split\n",
    "\n",
    "fnexpr='exprLOW.csv'\n",
    "fnmet='methylLOW.csv'\n",
    "fnassig='assignLOW.csv'\n",
    "nsamp=10000\n",
    "fnmodel='ETMTRANSF12-10K.pth'\n",
    "\n",
    "\n",
    "#Función para contar número de parámetros del modelo\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "# Definir el modelo Transformer\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "\n",
    "        self.encoder = nn.Linear(input_dim, nhid)\n",
    "        self.transformer_encoder = TransformerEncoder(TransformerEncoderLayer(nhid, nhead, nhid, dropout), nlayers)\n",
    "        self.decoder = nn.Linear(nhid, output_dim)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "        \n",
    "# Leer datos\n",
    "expression_data = pd.read_csv(fnexpr)\n",
    "methylation_data = pd.read_csv(fnmet)\n",
    "assign_data = pd.read_csv(fnassig)\n",
    "\n",
    "expression_data = expression_data.iloc[:, 1:]\n",
    "methylation_data = methylation_data.iloc[:, 1:]\n",
    "assign_data = assign_data.iloc[:, 2:]\n",
    "\n",
    "# Convertir todas las columnas a tipo float\n",
    "expression_data = expression_data.apply(pd.to_numeric, errors='coerce')\n",
    "methylation_data = methylation_data.apply(pd.to_numeric, errors='coerce')\n",
    "assign_data = assign_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Lidiar con valores NaN (si los hay). Pone 0(CAMBIAR)\n",
    "#expression_data.fillna(0, inplace=True)\n",
    "#methylation_data.fillna(0, inplace=True)\n",
    "#assign_data.fillna(0, inplace=True)\n",
    "\n",
    "#Normalizamos\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Asumiendo que expression_data, methylation_data y assign_data son tus DataFrames\n",
    "expression_data_scaled = scaler.fit_transform(expression_data)\n",
    "methylation_data_scaled = scaler.fit_transform(methylation_data)\n",
    "assign_data_scaled =assign_data\n",
    "\n",
    "# Convertir a DataFrame\n",
    "expression_data = pd.DataFrame(expression_data_scaled, index=expression_data.index, columns=expression_data.columns)\n",
    "methylation_data = pd.DataFrame(methylation_data_scaled, index=methylation_data.index, columns=methylation_data.columns)\n",
    "assign_data = pd.DataFrame(assign_data_scaled, index=assign_data.index, columns=assign_data.columns)\n",
    "\n",
    "#print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\"\n",
    "\n",
    "expression_data_tensor = torch.FloatTensor(expression_data.values).to(device)\n",
    "methylation_data_tensor = torch.FloatTensor(methylation_data.values).to(device)\n",
    "assign_data_tensor = torch.FloatTensor(assign_data.values).to(device)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "dataset = TensorDataset(expression_data_tensor, methylation_data_tensor)\n",
    "train_size = int(0.9 * len(dataset))  # Ajusta esto según tu necesidad\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Convertir los Subset en tensores para el entrenamiento\n",
    "expression_train, methylation_train= zip(*[(e, m) for e, m in train_dataset])\n",
    "expression_train = torch.stack(expression_train)\n",
    "methylation_train = torch.stack(methylation_train)\n",
    "#assign_train = torch.stack(assign_train)\n",
    "\n",
    "# Convertir los Subset en tensores para la validación/prueba\n",
    "expression_test, methylation_test = zip(*[(e, m) for e, m in test_dataset])\n",
    "expression_test = torch.stack(expression_test)\n",
    "methylation_test = torch.stack(methylation_test)\n",
    "#assign_test = torch.stack(assign_test)\n",
    "input_dim = expression_data.shape[1]\n",
    "output_dim = methylation_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d3896-e768-4b62-ae06-ddf92e142812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fede/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.1041\n",
      "Saved model with Train Loss: 0.104123\n",
      "Epoch 2, Train Loss: 0.0537\n",
      "Saved model with Train Loss: 0.053744\n",
      "Epoch 3, Train Loss: 0.0433\n",
      "Saved model with Train Loss: 0.043284\n",
      "Epoch 4, Train Loss: 0.0449\n",
      "Epoch 5, Train Loss: 0.0415\n",
      "Saved model with Train Loss: 0.041533\n",
      "Epoch 6, Train Loss: 0.0412\n",
      "Saved model with Train Loss: 0.041199\n",
      "Epoch 7, Train Loss: 0.0411\n",
      "Saved model with Train Loss: 0.041099\n",
      "Epoch 8, Train Loss: 0.0407\n",
      "Saved model with Train Loss: 0.040690\n",
      "Epoch 9, Train Loss: 0.0408\n",
      "Epoch 10, Train Loss: 0.0310\n",
      "Saved model with Train Loss: 0.031025\n",
      "Epoch 11, Train Loss: 0.0149\n",
      "Saved model with Train Loss: 0.014948\n",
      "Epoch 12, Train Loss: 0.0145\n",
      "Saved model with Train Loss: 0.014483\n",
      "Epoch 13, Train Loss: 0.0145\n",
      "Epoch 14, Train Loss: 0.0142\n",
      "Saved model with Train Loss: 0.014191\n",
      "Epoch 15, Train Loss: 0.0141\n",
      "Saved model with Train Loss: 0.014135\n",
      "Epoch 16, Train Loss: 0.0140\n",
      "Saved model with Train Loss: 0.014007\n",
      "Epoch 17, Train Loss: 0.0140\n",
      "Saved model with Train Loss: 0.013999\n",
      "Epoch 18, Train Loss: 0.0139\n",
      "Saved model with Train Loss: 0.013908\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parámetros del Transformer\n",
    "\n",
    "nhead = 8  # Número de cabezas en el multiheadattention\n",
    "nhid = 1024  # Dimensión oculta\n",
    "nlayers = 4  # Número de capas TransformerEncoderLayer\n",
    "dropout = 0.2  # Probabilidad de dropout\n",
    "\n",
    "\n",
    "# Crear instancia del modelo\n",
    "model = TransformerModel(input_dim, output_dim, nhead, nhid, nlayers, dropout).to(device)\n",
    "\n",
    "# Hiperparámetros y optimizador\n",
    "lr = 0.0002  # Tasa de aprendizaje\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Entrenamiento\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = torch.triu(torch.ones(sz, sz), 1)\n",
    "    mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "    return mask\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in data_loader:\n",
    "        expression_data, methylation_data = batch\n",
    "        expression_data = expression_data.to(device)\n",
    "        methylation_data = methylation_data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        src_mask = generate_square_subsequent_mask(expression_data.size(0)).to(device)\n",
    "        output = model(expression_data, src_mask)\n",
    "        loss = criterion(output, methylation_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            expression_data, methylation_data = batch\n",
    "            expression_data = expression_data.to(device)\n",
    "            methylation_data = methylation_data.to(device)\n",
    "            src_mask = generate_square_subsequent_mask(expression_data.size(0)).to(device)\n",
    "            output = model(expression_data, src_mask)\n",
    "            loss = criterion(output, methylation_data)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Configuración del entrenamiento\n",
    "n_epochs = 100  # Número de épocas\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    #test_loss = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}')\n",
    "\n",
    "    # Guardar el modelo si es el mejor hasta ahora\n",
    "    if train_loss < best_val_loss:\n",
    "        best_val_loss = train_loss\n",
    "        torch.save(model.state_dict(), fnmodel)\n",
    "        print(f\"Saved model with Train Loss: {train_loss:.6f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be72300-c585-4101-b1f9-9ff6cb527c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.nn.functional import mse_loss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import wasserstein_distance, ks_2samp\n",
    "import sys\n",
    "import umap\n",
    "# Leer datos\n",
    "#expression_data_test_tensor, methylation_data_test_tensor = zip(*[(e, m) for e, m in test_dataset])\n",
    "\n",
    "\n",
    "# Convertir los tensores a numpy y luego a DataFrame de pandas\n",
    "expression_data_test_np = expression_test.cpu().numpy()\n",
    "methylation_data_test_np = methylation_test.cpu().numpy()\n",
    "\n",
    "#expression_data_test_tensor = torch.FloatTensor(expression_data_test_np).to(device)\n",
    "expression_data_test_df = pd.DataFrame(expression_data_test_np)\n",
    "methylation_data_test_df = pd.DataFrame(methylation_data_test_np)\n",
    "\n",
    "\n",
    "\n",
    "X_real = pd.concat([expression_data_test_df, methylation_data_test_df], axis=1)\n",
    "# Concatenar los datos\n",
    "#combined_data =torch.FloatTensor(np.hstack((expression_data, methylation_data,assign_data)))\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\"\n",
    "\n",
    "# Cargar el modelo Transformer previamente entrenado\n",
    "model = TransformerModel(input_dim, output_dim, nhead, nhid, nlayers, dropout).to(device)  # Asegúrate de proporcionar los parámetros correctos aquí\n",
    "model.load_state_dict(torch.load(fnmodel))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Preparar los datos de expresión para la inferencia\n",
    "#expression_data_test_tensor = torch.FloatTensor(expression_data_test.values).to(device)\n",
    "\n",
    "# Generar datos de metilación utilizando el modelo Transformer\n",
    "with torch.no_grad():\n",
    "    # Necesitamos crear una máscara de secuencia para la inferencia\n",
    "    src_mask = generate_square_subsequent_mask(expression_test.size(0)).to(device)\n",
    "    generated_methyl = model(expression_test, src_mask)\n",
    "\n",
    "# Convertir los datos generados a formato numpy\n",
    "generated_methyl = generated_methyl.cpu().numpy()\n",
    "\n",
    "# Suponiendo que la primera parte de la salida generada corresponde a los datos de metilación\n",
    "generated_methyl_data = generated_methyl[:, :methylation_test.shape[1]]\n",
    "\n",
    "# Convertir a DataFrame de pandas\n",
    "generated_methyl_data_df = pd.DataFrame(generated_methyl_data)\n",
    "\n",
    "X_gan = pd.concat([expression_data_test_df, generated_methyl_data_df], axis=1)\n",
    "#last_column = X_gan.columns[-1]\n",
    "#X_gan = X_gan.drop(columns=[last_column])\n",
    "X_gan.columns = X_real.columns\n",
    "# Concatena los datos reales con los generados\n",
    "X_combined = np.vstack([X_real, X_gan])\n",
    "\n",
    "#generated_methyl_data_np = generated_methyl_data.cpu().numpy()\n",
    "\n",
    "# Calcular el MSE\n",
    "mse = mean_squared_error(methylation_data_test_np, generated_methyl_data)\n",
    "\n",
    "print(f\"MSE entre los datos de metilación reales y los generados: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8b7b5-c373-4a86-9b69-eb5ddebd998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate([np.ones(X_real.shape[0]), np.zeros(X_gan.shape[0])])\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_combined)\n",
    "\n",
    "plt.scatter(X_tsne[labels==1, 0], X_tsne[labels==1, 1], c='blue', label='Real', s=3)\n",
    "plt.scatter(X_tsne[labels==0, 0], X_tsne[labels==0, 1], c='red', label='Generated', s=3)\n",
    "plt.legend()\n",
    "plt.title('t-SNE visualization')\n",
    "#plt.savefig(filename+\"tsne.jpg\")\n",
    "plt.show()\n",
    "\n",
    "# Configurando y entrenando UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "X_umap = umap_model.fit_transform(X_combined)\n",
    "\n",
    "# Dibujando la visualización\n",
    "plt.scatter(X_umap[labels==1, 0], X_umap[labels==1, 1], c='blue', label='Real', s=3)\n",
    "plt.scatter(X_umap[labels==0, 0], X_umap[labels==0, 1], c='red', label='Generated', s=3)\n",
    "plt.legend()\n",
    "plt.title('UMAP visualization')\n",
    "#plt.savefig(filename+\"umap.jpg\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_combined)\n",
    "\n",
    "plt.scatter(X_pca[labels==1, 0], X_pca[labels==1, 1], c='blue', label='Real', s=3)\n",
    "plt.scatter(X_pca[labels==0, 0], X_pca[labels==0, 1], c='red', label='Generated', s=3)\n",
    "plt.legend()\n",
    "plt.title('PCA visualization')\n",
    "#plt.savefig(filename+\"pca.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaef2b3-ab07-4354-a354-d1a8434bdec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
