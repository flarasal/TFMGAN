{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefe2b6d-ee4c-44a3-b1f2-2dda2ca33fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade19a53-9154-49af-a8d1-6136ad278adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from torch.utils.data import TensorDataset,DataLoader, random_split\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "fnexpr='exprLOW.csv'\n",
    "fnmet='methylLOW.csv'\n",
    "fnassig='assignLOW.csv'\n",
    "nsamp=10000\n",
    "fnmodel='MTETRWDNM1-10K.pth'\n",
    "\n",
    "\n",
    "#Función para contar número de parámetros del modelo\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "# Definir el modelo Transformer\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, nhead, nhid, nlayers, decoder_layers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.tgt_mask = None\n",
    "\n",
    "        self.encoder = nn.Linear(input_dim, nhid)\n",
    "        self.transformer_encoder = TransformerEncoder(TransformerEncoderLayer(nhid, nhead, nhid, dropout), nlayers)\n",
    "\n",
    "        self.decoder_input = nn.Linear(output_dim, nhid)\n",
    "        self.transformer_decoder = TransformerDecoder(TransformerDecoderLayer(nhid, nhead, nhid, dropout), decoder_layers)\n",
    "        self.output_layer = nn.Linear(nhid, output_dim)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.encoder(src)\n",
    "        memory = self.transformer_encoder(src)\n",
    "\n",
    "        tgt = self.decoder_input(tgt)\n",
    "        output = self.transformer_decoder(tgt, memory)\n",
    "        output = self.output_layer(output)\n",
    "        return output\n",
    "        \n",
    "# Leer datos\n",
    "expression_data = pd.read_csv(fnexpr)\n",
    "methylation_data = pd.read_csv(fnmet)\n",
    "assign_data = pd.read_csv(fnassig)\n",
    "\n",
    "expression_data = expression_data.iloc[:, 1:]\n",
    "methylation_data = methylation_data.iloc[:, 1:]\n",
    "assign_data = assign_data.iloc[:, 2:]\n",
    "\n",
    "# Convertir todas las columnas a tipo float\n",
    "expression_data = expression_data.apply(pd.to_numeric, errors='coerce')\n",
    "methylation_data = methylation_data.apply(pd.to_numeric, errors='coerce')\n",
    "assign_data = assign_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Lidiar con valores NaN (si los hay). Pone 0(CAMBIAR)\n",
    "#expression_data.fillna(0, inplace=True)\n",
    "#methylation_data.fillna(0, inplace=True)\n",
    "#assign_data.fillna(0, inplace=True)\n",
    "\n",
    "#Normalizamos\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "expression_data_scaled = scaler.fit_transform(expression_data)\n",
    "methylation_data_scaled = scaler.fit_transform(methylation_data)\n",
    "assign_data_scaled =assign_data\n",
    "\n",
    "# Convertir a DataFrame\n",
    "expression_data = pd.DataFrame(expression_data_scaled, index=expression_data.index, columns=expression_data.columns)\n",
    "methylation_data = pd.DataFrame(methylation_data_scaled, index=methylation_data.index, columns=methylation_data.columns)\n",
    "assign_data = pd.DataFrame(assign_data_scaled, index=assign_data.index, columns=assign_data.columns)\n",
    "\n",
    "#print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\"\n",
    "\n",
    "expression_data_tensor = torch.FloatTensor(expression_data.values).to(device)\n",
    "methylation_data_tensor = torch.FloatTensor(methylation_data.values).to(device)\n",
    "assign_data_tensor = torch.FloatTensor(assign_data.values).to(device)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "dataset = TensorDataset(expression_data_tensor, methylation_data_tensor)\n",
    "train_size = int(0.9 * len(dataset))  # Ajusta esto según tu necesidad\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Convertir los Subset en tensores para el entrenamiento\n",
    "expression_train, methylation_train= zip(*[(e, m) for e, m in train_dataset])\n",
    "expression_train = torch.stack(expression_train)\n",
    "methylation_train = torch.stack(methylation_train)\n",
    "#assign_train = torch.stack(assign_train)\n",
    "\n",
    "# Convertir los Subset en tensores para la validación/prueba\n",
    "expression_test, methylation_test = zip(*[(e, m) for e, m in test_dataset])\n",
    "expression_test = torch.stack(expression_test)\n",
    "methylation_test = torch.stack(methylation_test)\n",
    "#assign_test = torch.stack(assign_test)\n",
    "input_dim = methylation_data.shape[1]\n",
    "output_dim = expression_data.shape[1]\n",
    "# Parámetros del Transformer\n",
    "\n",
    "nhead = 8  # Número de cabezas en el multiheadattention\n",
    "nhid = 2048  # Dimensión oculta\n",
    "nlayers = 4  # Número de capas TransformerEncoderLayer\n",
    "dropout = 0.2  # Probabilidad de dropout\n",
    "# Entrenamiento\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = torch.triu(torch.ones(sz, sz), 1)\n",
    "    mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86d3896-e768-4b62-ae06-ddf92e142812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fede/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.0517\n",
      "Saved model with Train Loss: 0.051706\n",
      "Epoch 2, Train Loss: 0.0275\n",
      "Saved model with Train Loss: 0.027451\n",
      "Epoch 3, Train Loss: 0.0246\n",
      "Saved model with Train Loss: 0.024567\n",
      "Epoch 4, Train Loss: 0.0222\n",
      "Saved model with Train Loss: 0.022216\n",
      "Epoch 5, Train Loss: 0.0203\n",
      "Saved model with Train Loss: 0.020262\n",
      "Epoch 6, Train Loss: 0.0184\n",
      "Saved model with Train Loss: 0.018350\n",
      "Epoch 7, Train Loss: 0.0169\n",
      "Saved model with Train Loss: 0.016946\n",
      "Epoch 8, Train Loss: 0.0158\n",
      "Saved model with Train Loss: 0.015840\n",
      "Epoch 9, Train Loss: 0.0145\n",
      "Saved model with Train Loss: 0.014464\n",
      "Epoch 10, Train Loss: 0.0134\n",
      "Saved model with Train Loss: 0.013426\n",
      "Epoch 11, Train Loss: 0.0123\n",
      "Saved model with Train Loss: 0.012271\n",
      "Epoch 12, Train Loss: 0.0116\n",
      "Saved model with Train Loss: 0.011560\n",
      "Epoch 13, Train Loss: 0.0106\n",
      "Saved model with Train Loss: 0.010630\n",
      "Epoch 14, Train Loss: 0.0099\n",
      "Saved model with Train Loss: 0.009909\n",
      "Epoch 15, Train Loss: 0.0092\n",
      "Saved model with Train Loss: 0.009233\n",
      "Epoch 16, Train Loss: 0.0084\n",
      "Saved model with Train Loss: 0.008376\n",
      "Epoch 17, Train Loss: 0.0077\n",
      "Saved model with Train Loss: 0.007681\n",
      "Epoch 18, Train Loss: 0.0070\n",
      "Saved model with Train Loss: 0.006958\n",
      "Epoch 19, Train Loss: 0.0064\n",
      "Saved model with Train Loss: 0.006387\n",
      "Epoch 20, Train Loss: 0.0058\n",
      "Saved model with Train Loss: 0.005800\n",
      "Epoch 21, Train Loss: 0.0053\n",
      "Saved model with Train Loss: 0.005338\n",
      "Epoch 22, Train Loss: 0.0049\n",
      "Saved model with Train Loss: 0.004907\n",
      "Epoch 23, Train Loss: 0.0045\n",
      "Saved model with Train Loss: 0.004508\n",
      "Epoch 24, Train Loss: 0.0043\n",
      "Saved model with Train Loss: 0.004262\n",
      "Epoch 25, Train Loss: 0.0039\n",
      "Saved model with Train Loss: 0.003878\n",
      "Epoch 26, Train Loss: 0.0037\n",
      "Saved model with Train Loss: 0.003667\n",
      "Epoch 27, Train Loss: 0.0035\n",
      "Saved model with Train Loss: 0.003524\n",
      "Epoch 28, Train Loss: 0.0033\n",
      "Saved model with Train Loss: 0.003337\n",
      "Epoch 29, Train Loss: 0.0031\n",
      "Saved model with Train Loss: 0.003134\n",
      "Epoch 30, Train Loss: 0.0030\n",
      "Saved model with Train Loss: 0.002994\n",
      "Epoch 31, Train Loss: 0.0029\n",
      "Saved model with Train Loss: 0.002854\n",
      "Epoch 32, Train Loss: 0.0027\n",
      "Saved model with Train Loss: 0.002732\n",
      "Epoch 33, Train Loss: 0.0026\n",
      "Saved model with Train Loss: 0.002646\n",
      "Epoch 34, Train Loss: 0.0026\n",
      "Saved model with Train Loss: 0.002554\n",
      "Epoch 35, Train Loss: 0.0024\n",
      "Saved model with Train Loss: 0.002421\n",
      "Epoch 36, Train Loss: 0.0023\n",
      "Saved model with Train Loss: 0.002339\n",
      "Epoch 37, Train Loss: 0.0022\n",
      "Saved model with Train Loss: 0.002224\n",
      "Epoch 38, Train Loss: 0.0021\n",
      "Saved model with Train Loss: 0.002142\n",
      "Epoch 39, Train Loss: 0.0021\n",
      "Saved model with Train Loss: 0.002104\n",
      "Epoch 40, Train Loss: 0.0020\n",
      "Saved model with Train Loss: 0.002027\n",
      "Epoch 41, Train Loss: 0.0019\n",
      "Saved model with Train Loss: 0.001924\n",
      "Epoch 42, Train Loss: 0.0019\n",
      "Saved model with Train Loss: 0.001908\n",
      "Epoch 43, Train Loss: 0.0018\n",
      "Saved model with Train Loss: 0.001789\n",
      "Epoch 44, Train Loss: 0.0018\n",
      "Saved model with Train Loss: 0.001753\n",
      "Epoch 45, Train Loss: 0.0017\n",
      "Saved model with Train Loss: 0.001740\n",
      "Epoch 46, Train Loss: 0.0017\n",
      "Saved model with Train Loss: 0.001657\n",
      "Epoch 47, Train Loss: 0.0016\n",
      "Saved model with Train Loss: 0.001573\n",
      "Epoch 48, Train Loss: 0.0016\n",
      "Saved model with Train Loss: 0.001570\n",
      "Epoch 49, Train Loss: 0.0015\n",
      "Saved model with Train Loss: 0.001496\n",
      "Epoch 50, Train Loss: 0.0015\n",
      "Saved model with Train Loss: 0.001470\n",
      "Epoch 51, Train Loss: 0.0014\n",
      "Saved model with Train Loss: 0.001387\n",
      "Epoch 52, Train Loss: 0.0014\n",
      "Saved model with Train Loss: 0.001386\n",
      "Epoch 53, Train Loss: 0.0013\n",
      "Saved model with Train Loss: 0.001341\n",
      "Epoch 54, Train Loss: 0.0013\n",
      "Saved model with Train Loss: 0.001306\n",
      "Epoch 55, Train Loss: 0.0012\n",
      "Saved model with Train Loss: 0.001234\n",
      "Epoch 56, Train Loss: 0.0012\n",
      "Saved model with Train Loss: 0.001191\n",
      "Epoch 57, Train Loss: 0.0012\n",
      "Saved model with Train Loss: 0.001156\n",
      "Epoch 58, Train Loss: 0.0011\n",
      "Saved model with Train Loss: 0.001133\n",
      "Epoch 59, Train Loss: 0.0011\n",
      "Saved model with Train Loss: 0.001102\n",
      "Epoch 60, Train Loss: 0.0011\n",
      "Saved model with Train Loss: 0.001085\n",
      "Epoch 61, Train Loss: 0.0011\n",
      "Saved model with Train Loss: 0.001076\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Bucle de entrenamiento\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m---> 41\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Guardar el modelo si es el mejor hasta ahora\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 26\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear instancia del modelo\n",
    "model = TransformerModel(input_dim, output_dim, nhead, nhid, nlayers,nlayers, dropout).to(device)\n",
    "\n",
    "# Hiperparámetros y optimizador\n",
    "lr = 0.00002  # Tasa de aprendizaje\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in data_loader:\n",
    "        expression_data, methylation_data = batch\n",
    "        expression_data = expression_data.to(device)\n",
    "        methylation_data = methylation_data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(methylation_data, expression_data)\n",
    "        #print(output)\n",
    "        loss = criterion(output, expression_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Configuración del entrenamiento\n",
    "n_epochs = 100  # Número de épocas\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}')\n",
    "\n",
    "    # Guardar el modelo si es el mejor hasta ahora\n",
    "    if train_loss < best_val_loss:\n",
    "        best_val_loss = train_loss\n",
    "        torch.save(model.state_dict(), fnmodel)\n",
    "        print(f\"Saved model with Train Loss: {train_loss:.6f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be72300-c585-4101-b1f9-9ff6cb527c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fede/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1000x367 and 131x2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Realizar la predicción\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 55\u001b[0m     generated_expr \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethylation_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethylation_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Convertir los datos generados a formato numpy\u001b[39;00m\n\u001b[1;32m     60\u001b[0m generated_expr \u001b[38;5;241m=\u001b[39m generated_expr\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m     37\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src)\n\u001b[1;32m     38\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder(src)\n\u001b[0;32m---> 40\u001b[0m tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_decoder(tgt, memory)\n\u001b[1;32m     42\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(output)\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/PyEnv/PB/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1000x367 and 131x2048)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.nn.functional import mse_loss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import wasserstein_distance, ks_2samp\n",
    "import sys\n",
    "import umap\n",
    "from scipy.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "# Convertir los tensores a numpy y luego a DataFrame de pandas\n",
    "expression_data_test_np = expression_test.cpu().numpy()\n",
    "methylation_data_test_np = methylation_test.cpu().numpy()\n",
    "\n",
    "expression_data_test_df = pd.DataFrame(expression_data_test_np)\n",
    "methylation_data_test_df = pd.DataFrame(methylation_data_test_np)\n",
    "\n",
    "X_real = pd.concat([expression_data_test_df, methylation_data_test_df], axis=1)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device=\"cpu\"\n",
    "\n",
    "# Cargar el modelo Transformer previamente entrenado\n",
    "model = TransformerModel(input_dim, output_dim, nhead, nhid, nlayers,nlayers, dropout).to(device)  # Asegúrate de proporcionar los parámetros correctos aquí\n",
    "model.load_state_dict(torch.load(fnmodel))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Generar datos de metilación utilizando el modelo Transformer\n",
    "src_mask = generate_square_subsequent_mask(methylation_test.size(0)).to(device)\n",
    "\n",
    "# Los datos objetivo (tgt) para la predicción pueden ser inicializados como ceros\n",
    "# Esto es un estándar en algunas implementaciones de modelos de secuencia a secuencia\n",
    "expression_pred = torch.randn_like(expression_test).to(device)\n",
    "\n",
    "# Realizar la predicción\n",
    "with torch.no_grad():\n",
    "    generated_expr = model(methylation_test, expression_pred)\n",
    "\n",
    "\n",
    "\n",
    "# Convertir los datos generados a formato numpy\n",
    "generated_expr = generated_expr.cpu().numpy()\n",
    "\n",
    "generated_expr_data = generated_expr[:, :expression_test.shape[1]]\n",
    "\n",
    "# Convertir a DataFrame de pandas\n",
    "generated_expr_data_df = pd.DataFrame(generated_expr_data)\n",
    "\n",
    "X_gan = pd.concat([generated_expr_data_df,methylation_data_test_df ], axis=1)\n",
    "\n",
    "X_gan.columns = X_real.columns\n",
    "\n",
    "# Concatena los datos reales con los generados\n",
    "X_combined = np.vstack([X_real, X_gan])\n",
    "#print(methylation_test)\n",
    "#print(expression_data_test_np)\n",
    "#print(generated_expr_data)\n",
    "# Calcular el MSE\n",
    "mse = mean_squared_error(expression_data_test_np, generated_expr_data)\n",
    "\n",
    "print(f\"MSE entre los datos de metilación reales y los generados: {mse}\")\n",
    "rmse = sqrt(mse)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "pcc, _ = pearsonr(expression_data_test_np.flatten(), generated_expr_data.flatten())\n",
    "print(f\"PCC: {pcc}\")\n",
    "\n",
    "#t-SNE\n",
    "labels = np.concatenate([np.ones(X_real.shape[0]), np.zeros(X_gan.shape[0])])\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_combined)\n",
    "\n",
    "plt.scatter(X_tsne[labels==1, 0], X_tsne[labels==1, 1], c='blue', label='Real', s=3)\n",
    "plt.scatter(X_tsne[labels==0, 0], X_tsne[labels==0, 1], c='red', label='Generated', s=3)\n",
    "plt.legend()\n",
    "plt.title('t-SNE visualization')\n",
    "#plt.savefig(filename+\"tsne.jpg\")\n",
    "plt.show()\n",
    "\n",
    "# Configurando y entrenando UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "X_umap = umap_model.fit_transform(X_combined)\n",
    "\n",
    "# Dibujando la visualización\n",
    "plt.scatter(X_umap[labels==1, 0], X_umap[labels==1, 1], c='blue', label='Real', s=3)\n",
    "plt.scatter(X_umap[labels==0, 0], X_umap[labels==0, 1], c='red', label='Generated', s=3)\n",
    "plt.legend()\n",
    "plt.title('UMAP visualization')\n",
    "#plt.savefig(filename+\"umap.jpg\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_combined)\n",
    "\n",
    "plt.scatter(X_pca[labels==1, 0], X_pca[labels==1, 1], c='blue', label='Real', s=3)\n",
    "plt.scatter(X_pca[labels==0, 0], X_pca[labels==0, 1], c='red', label='Generated', s=3)\n",
    "plt.legend()\n",
    "plt.title('PCA visualization')\n",
    "#plt.savefig(filename+\"pca.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f0a3f-11ca-4d37-b3d0-3793814f8caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
